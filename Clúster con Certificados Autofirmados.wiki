
= Guía de Instalación de Kafka =

El personal objetivo para esta página es el Departamento Data Services & Cloud.

El objetivo de esta página es servir de guía para la instalación de Kafka en un clúster de servidores Linux en On-Premise utilizando certificados auto-firmados.

&nbsp;

&nbsp;

== Condideraciones Previas ==

*Se requiere usuario root o sudoer. 
*La versión de Kafka utilizada es la 3.7.0 con Scala 2.13. 
*A partir de la versión 4 de Kafka, Zookeeper pasará a descontinuarse, por lo que esta guía no será válida para versiones posteriores. 
*La versión de Java utilizada es la 17 siguiendo las notificaciones de obsolencia de las versiones 8 y 11. 
*Las instalaciones se realizan manualmente debido a que el usuario sudoer utilizado en la práctica carecía de permisos para descargar paquetes. 
*Se incluye un apartado de montaje de disco debido a que las máquinas utilizadas en la práctica disponían de un disco adicional para almacenar los logs de Kafka, pero no estaba montado en el sistema operativo. 

&nbsp;

&nbsp;

== Datos de las Máquinas ==

*Se utilizan tres máquinas con las siguientes características: 
**'''ln01kafklog01''' (10.1.178.111): Máquina que actúa como CA y Broker de Kafka. (A lo largo de la guía seguirá siendo así, pero en la práctica, ahora todas las máquinas pueden actuar como CA al disponer de los ficheros necesarios en la ruta <code>/opt/kafka/ssl/CA-files</code>) 
**'''ln01kafklog02''' (10.1.178.112): Máquina que actúa como Broker de Kafka. 
**'''ln91kafklog01''' (10.1.178.113): Máquina que actúa como Broker de Kafka. 
**'''ln01kafklog03''' (10.1.178.116): Máquina que actúa como Broker de Kafka. 
**'''ln91kafklog02''' (&nbsp;10.1.178.115): Máquina que actúa como Broker de Kafka.   
*Todas las máquinas disponen de 12GB de RAM y 4 CPUs y un disco de 50GB para el sistema operativo. Incluyen, además, un disco adicional de 100GB para almacenar los logs de Kafka, que se reparte en dos volúmenes lógicos: uno de 5GB para Zookeeper y otro de aproximadamente 95GB para los logs de Kafka. 
*Se utiliza el usuario <code>kafka</code> (bajo un grupo con el mismo nombre) para la instalación de Kafka. 
*Las máquinas son accesibles por SSH desde la máquina de salto <code>10.1.228.20</code>. 
*Se utiliza Java 17 siguiendo las notificaciones de obsolencia de las versiones 8 y 11. 
*Se utilizan certificados auto-firmados para la comunicación segura entre los nodos de Kafka. 
*Tanto el certificado de la CA como los certificados de los nodos de Kafka se generan en el directorio <code>/opt/kafka/ssl</code> del usuario <code>kafka</code>. Los ficheros relativos a la CA se almacenan en el directorio<code>/opt/kafka/ssl/CA-files</code>. 
*Los certificados tienen una validez de 10 años (hasta aproximadamente el 18 de Abril de 2034). 
*Las configuraciones de kafka se encuentran en el directorio<code>/opt/kafka/kafka-config</code> bajo los nombres <code>zookeeper.properties</code> y <code>kafka.properties</code>. 

&nbsp;

== Preparación del Sistema ==

Los siguientes pasos son necesarios para preparar el sistema antes de instalar Kafka y deben realizarse con un usuario con permisos de sudo.

&nbsp;

=== Creación de Usuario y Grupo ===

Se creará un usuario y un grupo para Kafka con el fin de minimizar los riesgos de seguridad debido a privilegios elevados.

&nbsp;
<syntaxhighlight lang="bash">username="kafka"
groupname="kafka"

sudo groupadd "$groupname" && \
  sudo useradd -m -g "$groupname" "$username" && \
  sudo passwd "$username"

# Para cambiar de usuario: 
# su - <usuario></syntaxhighlight>

=== Montaje de Disco ===

En caso de que se disponga de un disco adicional para almacenar los logs de Kafka, se debe montar en el sistema operativo.

En este caso, el disco adicional es de 100GB y se repartirá en dos volúmenes lógicos: uno de 5GB para Zookeeper y otro de aproximadamente 95GB (24319 extensiones frente a 24320 necesarias para ser 95GB exactos) para los logs de Kafka.

&nbsp;
<syntaxhighlight lang="bash"># Se puede comprobar la existencia y estado de los discos con el comando:  lsblk

# Si es necesario formatear el disco, se puede hacer con el comando:
# sudo fdisk <disco>
# Por ejemplo: sudo fdisk /dev/sdb
# ---- En la consola interactiva de fdisk se deben utilizar las siguientes opciones, respetando el orden ----
# d
# w


# Crear volumen físico (physical volume ó pv)
disk="/dev/sdb"
# sudo pvcreate <disk> 
sudo pvcreate "$disk"
# Se puede comprobar utilizando: sudo pvs <disk>

# Crear "volume group"
vgname="vgsystem01"
# sudo vgcreate <vg_name> <pv>
sudo vgcreate "$vgname" "$disk"
# Se puede comprobar utilizando: sudo vgs <vg_name>


# Crear "logical volume"
zookeeper_lvm_name="zookeeper"
zookeeper_lvm_size="5G"
kafka_lvm_name="kafka-logs"
kafka_lvm_extensions=24319
# sudo lvcreate -L <lv-size> -n <lv-name> <vg-name>
sudo lvcreate -L "$zookeeper_lvm_size" -n "$zookeeper_lvm_name" "$vgname"
# Para poder utilizar el resto del disco, se asignará el espacio en función de la extensión del disco:
# sudo lvcreate -l <extensions> -n <lv-name> <vg-name>
sudo lvcreate -l $kafka_lvm_extensions -n "$kafka_lvm_name" "$vgname"
# Se puede comprobar la creación utilizando: sudo lvs <full-ls-name>
sudo lvs "/dev/$vgname/$zookeeper_lvm_name"
sudo lvs "/dev/$vgname/$kafka_lvm_name"


# Formatear los volúmenes lógicos a XFS
# mkfs.xfs <partition>
sudo mkfs.xfs "/dev/$vgname/$zookeeper_lvm_name"
sudo mkfs.xfs "/dev/$vgname/$kafka_lvm_name"


# Crear los directorios de montaje
username="kafka"
groupname="kafka"
zookeeper_mount_point="/zookeeper"
kafka_mount_point="/kafka-logs"
sudo mkdir -p "${zookeeper_mount_point}" && \
  sudo chown "$username:$groupname" "${zookeeper_mount_point}" && \
  sudo chmod 764 "${zookeeper_mount_point}" && \
  sudo mkdir -p "${kafka_mount_point}" && \
  sudo chown "$username:$groupname" "${kafka_mount_point}" && \
  sudo chmod 764 "${kafka_mount_point}"

# Incluir las particiones en /etc/fstab para que el disco se monte automáticamente en cada arranque
# --- Incluir una línea con el siguiente formato ---
# UUID="<id>" <mount-point> xfs defaults 0 0
# ó bien:
# <lv-full-path> <mouth-point> xfs defaults 0 0
# --- Ejemplo ---
# UUID="0142866f-bb15-4015-a201-4008ad631bca /kafka  xfs     defaults        0 0
sudo echo "/dev/$vgname/$zookeeper_lvm_name $zookeeper_mount_point xfs defaults 0 0" >> /etc/fstab
sudo echo "/dev/$vgname/$kafka_lvm_name $kafka_mount_point xfs defaults 0 0" >> /etc/fstab

# Montar todos los discos
sudo mount -a
# Reiniciar el daemon para que los cambios surtan efecto
sudo systemctl daemon-reload</syntaxhighlight>

&nbsp;

=== Instalación de Java ===

Se instalará Java 17 siguiendo las notificaciones de obsolencia de las versiones 8 y 11.

Se usará el paquete de OpenJDK 17 compilado por RedHat. '''Importante: '''La máquina debe estar registrada en RedHat para poder hacer uso de la paquetería.
<syntaxhighlight lang="bash">sudo dnf update -y && sudo dnf install -y java-17-openjdk</syntaxhighlight>

== Preparación de Certificados ==

Todos los ficheros se generarán en el directorio <code>/opt/kafka/ssl.</code>

=== Creación de CA ===

Se crean los ficheros ca-key y ca-cert para la autoridad certificadora. Esto debe realizarse '''una única vez''' en la máquina que actuará como CA.

Se ha establecido una validez de 10 años para los certificados (hasta aproximadamente el 18 de Abril de 2034).
<syntaxhighlight lang="bash">mkdir -p /opt/kafka/ssl/CA-files && cd /opt/kafka/ssl/CA-files && \
  openssl req -new -newkey rsa:4096 -days 3652 -x509 \
          -subj "/CN=Kafka-Security-CA" -keyout ca-key \
          -out ca-cert -nodes</syntaxhighlight>

=== Generación de Keystore y Petición de Firma ===

Se genera un Keystore para almacenar los certificados y poder generar una petición de firma de certificado.

Esto debe realizarse en cada broker (nodo) de Kafka.
<syntaxhighlight lang="bash"># Variables
# Cambia el valor de common_name por el nombre del nodo en la red
common_name="ln01kafklog01"
pass="!!sustituir_por_password!!"
cert_sign_request_file_name="signing-request-file"

# Se crean los directorios donde almacenar los ficheros para ssl
mkdir -p /opt/kafka/ssl/CA-files && cd /opt/kafka/ssl/

# Create keystore
keytool -genkey -keystore kafka.server.keystore.jks \
        -keyalg RSA -validity 3652 -storepass "$pass" \
        -keypass "$pass" -dname "CN=$common_name" \
        -storetype pkcs12
        
# Create sign request
keytool -keystore kafka.server.keystore.jks -certreq \
        -file "$cert_sign_request_file_name" -storepass "$pass" \
        -keypass "$pass"</syntaxhighlight>

=== Transferencia de Petición de Firma a Entidad Certificadora ===

Se debe transferir la petición de firma de certificado a la entidad certificadora para que sea firmada.
<syntaxhighlight lang="bash">cert_sign_request_file_name="signing-request-file"
username="kafka"
ca_machinename="ln01kafklog01"
scp "$cert_sign_request_file_name" "$username@$ca_machinename:/opt/kafka/ssl/sign-request"</syntaxhighlight>

&nbsp;

=== Firma de la Petición de Firma ===

En la máquina que actúa como entidad certificadora, se firma la petición de firma de certificado.
<syntaxhighlight lang="bash">pass="!!sustituir_por_password!!"
openssl x509 -req -CA CA-files/ca-cert -CAkey CA-files/ca-key \
        -in "sign-request" -out signed-cert \
        -days 365 -CAcreateserial -passin pass:"$pass"</syntaxhighlight>

&nbsp;

=== Transferencia de Certificado Firmado y Certificado Público de CA ===

Se debe transferir el certificado firmado y el certificado público de CA desde la máquina que actúa como CA al nodo que solicitó la firma.
<syntaxhighlight lang="bash">username="kafka"
node_machinename="ln01kafklog02"
scp signed-cert "$username@$node_machinename:/opt/kafka/ssl/signed-cert"
scp /opt/kafka/ssl/CA-files/ca-cert "$username@$node_machinename:/opt/kafka/ssl/CA-files/ca-cert"</syntaxhighlight>

&nbsp;

=== Importación de Certificado Firmado y Certificado Público de CA ===

En cada máquina que actúa como nodo de Kafka, se importa el certificado firmado y el certificado público de la CA en el keystore y truststore.
<syntaxhighlight lang="bash"># Add CA Certificate to truststore
keytool -keystore kafka.server.truststore.jks -alias CARoot \
        -import -file CA-files/ca-cert -storepass "$pass" \
        -keypass "$pass" -noprompt
# Add CA Certificate to keystore
keytool -keystore kafka.server.keystore.jks -alias CARoot \
        -import -file CA-files/ca-cert -storepass "$pass" \
        -keypass "$pass" -noprompt
# Add signed certificate to keystore
keytool -keystore kafka.server.keystore.jks -import -file signed-cert \
        -storepass "$pass" -keypass "$pass" \
        -noprompt</syntaxhighlight>

== Preparación de Kafka ==

Esta sección debe realizarse con el usuario creado previamente.

=== Descarga de Kafka ===

&nbsp;
<syntaxhighlight lang="bash">cd /opt/kafka && wget https://downloads.apache.org/kafka/3.7.0/kafka_2.13-3.7.0.tgz -O - | tar xfz -

## Añadir Kafka al PATH
echo 'PATH="$PATH:/opt/kafka/kafka_2.13-3.7.0/bin"' >> ~/.bashrc</syntaxhighlight>

=== Creación de Ficheros myid ===

En cada nodo (broker) del clúster de Kafka, se debe crear un fichero llamado <code>myid</code> en el directorio de datos de Zookeeper.

Este fichero debe contener un número único que identifique al nodo en el clúster de Zookeeper.
<syntaxhighlight lang="bash">zookeeper_mount_point="/zookeeper"
brokerID="1"
echo "$brokerID" > "${zookeeper_mount_point}/myid"</syntaxhighlight>

=== Configuración de Zookeeper ===

Se debe configurar Zookeeper en cada nodo del clúster de Kafka.

La configuración es la misma en todos los nodos.

Algunas consideraciones a tener en cuenta:

*El fichero de configuración puede llamarse de cualquier manera. 
*No deben usarse rutas relativas ni rutas que incluyan el carácter <code>~</code> para referenciar la ruta de home del usuario. 
*Las líneas marcadas con <code>#!!</code> deben ser modificadas según las necesidades del entorno. 
*Hay que sustituir <code>!!sustituir_por_password!!</code> por la contraseña del keystore y truststore. 

Contenido del fichero de configuración de Zookeeper:<code>/opt/kafka/kafka-config/zookeeper.properties</code>
<syntaxhighlight lang="bash"># Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# the directory where the snapshot is stored.
#!! Please change the dataDir to a directory that can be used to store the snapshot and logs
dataDir=/zookeeper
# the port at which the clients will connect
secureClientPort=2181
serverCnxnFactory=org.apache.zookeeper.server.NettyServerCnxnFactory
authProvider.x509=org.apache.zookeeper.server.auth.X509AuthenticationProvider
#!! Please change the ssl.keyStore.location and ssl.trustStore.location to the location of your keystore and truststore
ssl.keyStore.location=/opt/kafka/ssl/kafka.server.keystore.jks
ssl.keyStore.password=!!sustituir_por_password!!
ssl.trustStore.location=/opt/kafka/ssl/kafka.server.truststore.jks
ssl.trustStore.password=!!sustituir_por_password!!
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0
# Disable the adminserver by default to avoid port conflicts.
# Set the port to something non-conflicting if choosing to enable this
admin.enableServer=false
# admin.serverPort=8080
initLimit=10
syncLimit=5
#!! Please change the server.1, server.2, and server.3 to the IP addresses of your Zookeeper servers
#!! All of your Zookeeper servers must be listed in this file
server.1=ln01kafklog01:2888:3888
server.2=ln01kafklog02:2888:3888
server.3=ln91kafklog01:2888:3888</syntaxhighlight>

=== Configuración de Kafka ===

Se debe configurar Kafka en cada nodo del clúster de Kafka.

La configuración sufre ligeras variaciones en cada nodo.

Algunas consideraciones a tener en cuenta:

*El fichero de configuración puede llamarse de cualquier manera. 
*No deben usarse rutas relativas ni rutas que incluyan el carácter <code>~</code> para referenciar la ruta de home del usuario. 
*Las líneas marcadas con <code>#!!</code> deben ser modificadas según las necesidades del entorno. 
*Hay que sustituir <code>!!sustituir_por_password!!</code> por la contraseña del keystore y truststore. 

Contenido del fichero de configuración de Kafka:<code>/opt/kafka/kafka-config/kafka.properties</code>
<syntaxhighlight lang="bash"># Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#
# This configuration file is intended for use in ZK-based mode, where Apache ZooKeeper is required.
# See kafka.server.KafkaConfig for additional details and defaults
#

############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
#!! Change to your broker id
broker.id=1

############################# Socket Server Settings #############################

# The address the socket server listens on. If not configured, the host name will be equal to the value of
# java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.
#   FORMAT:
#     listeners = listener_name://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
#listeners=PLAINTEXT://:9092

# Listener name, hostname and port the broker will advertise to clients.
# If not set, it uses the value for "listeners".
#advertised.listeners=PLAINTEXT://your.host.name:9092

# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
num.network.threads=3

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600


############################# Log Basics #############################

# A comma separated list of directories under which to store log files
#!! Change to your kafka's log directory
log.dirs=/kafka-logs

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
offsets.topic.replication.factor=2
transaction.state.log.replication.factor=2
transaction.state.log.min.isr=2

############################# Log Flush Policy #############################

# Messages are immediately written to the filesystem but by default we only fsync() to sync
# the OS cache lazily. The following configurations control the flush of data to disk.
# There are a few important trade-offs here:
#    1. Durability: Unflushed data may be lost if you are not using replication.
#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.
#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.
# The settings below allow one to configure the flush policy to flush data after a period of time or
# every N messages (or both). This can be done globally and overridden on a per-topic basis.

# The number of messages to accept before forcing a flush of data to disk
#log.flush.interval.messages=10000

# The maximum amount of time a message can sit in a log before we force a flush
#log.flush.interval.ms=1000

############################# Log Retention Policy #############################

# The following configurations control the disposal of log segments. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated.
# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
# from the end of the log.

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log unless the remaining
# segments drop below log.retention.bytes. Functions independently of log.retention.hours.
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
#!! Change to your Zookeeper IP addresses
zookeeper.connect=ln01kafklog01:2181,ln01kafklog02:2181,ln91kafklog01:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=18000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0

auto.create.topics.enable=false

zookeeper.ssl.client.enable=true
zookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNetty
#!! Change to your keystore location and password
zookeeper.ssl.keystore.location=/opt/kafka/ssl/kafka.server.keystore.jks
zookeeper.ssl.keystore.password=!!sustituir_por_password!!
#!! Change to your truststore location and password
zookeeper.ssl.truststore.location=/opt/kafka/ssl/kafka.server.truststore.jks
zookeeper.ssl.truststore.password=!!sustituir_por_password!!

#!! Change the IP address and port to the IP address and port of the Kafka broker
listeners=SSL://ln01kafklog01:9092
security.inter.broker.protocol=SSL
#!! Change to your keystore location and password
ssl.keystore.location=/opt/kafka/ssl/kafka.server.keystore.jks
ssl.keystore.password=!!sustituir_por_password!!
#!! Change to your key password
ssl.key.password=!!sustituir_por_password!!
#!! Change to your truststore location and password
ssl.truststore.location=/opt/kafka/ssl/kafka.server.truststore.jks
ssl.truststore.password=!!sustituir_por_password!!
ssl.client.auth=required
ssl.enabled.protocols=TLSv1.2
ssl.truststore.type=JKS
ssl.keystore.type=JKS
ssl.secure.random.implementation=SHA1PRNG
ssl.endpoint.identification.algorithm=</syntaxhighlight>

=== Arranque de Zookeeper ===

En cada nodo del clúster de Kafka, se debe iniciar Zookeeper para comprobar que la configuración es correcta.
<syntaxhighlight lang="bash">zookeeper-server-start.sh /opt/kafka/kafka-config/zookeeper.properties</syntaxhighlight>

=== Arranque de Kafka ===

En cada nodo del clúster de Kafka, se debe iniciar Kafka para comprobar que la configuración es correcta.
<syntaxhighlight lang="bash">kafka-server-start.sh /opt/kafka/kafka-config/kafka.properties</syntaxhighlight>

=== Creación de Servicio de Zookeeper ===

Se crea un servicio de Zookeeper para que se inicie automáticamente al arrancar el sistema.

Se configura la variable de entorno <code>KAFKA_HEAP_OPTS</code> para asignar 3GB de memoria a Zookeeper, que se corresponde a la mitad de la memoria asignada a Kafka.

Fichero de servicio de Zookeeper: <code>/etc/systemd/system/zookeeper.service</code>
<syntaxhighlight lang="bash">[Unit]
Description=zookeeper
After=syslog.target network.target

[Service]
Type=simple

User=kafka
Group=kafka
Environment=KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:/opt/kafka/kafka-config/log4j.properties"
Environment=KAFKA_HEAP_OPTS="-Xmx3G -Xms3G"

ExecStart=/opt/kafka/kafka_2.13-3.7.0/bin/zookeeper-server-start.sh /opt/kafka/kafka-config/zookeeper.properties
ExecStop=/opt/kafka/kafka_2.13-3.7.0/bin/zookeeper-server-stop.sh

[Install]
WantedBy=multi-user.target</syntaxhighlight>

Una vez creado el fichero de servicio, se debe recargar el daemon de systemd y habilitar el servicio.
<syntaxhighlight lang="bash">sudo systemctl daemon-reload
sudo systemctl start zookeeper
# Comprobar que el servicio se ha iniciado correctamente
sudo systemctl status zookeeper
sudo systemctl enable zookeeper</syntaxhighlight>

&nbsp;

=== Creación de Servicio de Kafka ===

Se crea un servicio de Kafka para que se inicie automáticamente al arrancar el sistema.

Se configura la variable de entorno <code>KAFKA_HEAP_OPTS</code> para asignar 6GB de memoria a Kafka. Es la cantidad recomendada para la máquina utilizada en la práctica, de 12GB de RAM total.

Se configura la variable de entorno <code>JAVA_HOME</code> para que Kafka utilice java correctamente. Si no se establece, Kafka podría fallar al arrancar. El valor para esta variable puede obtenerse con el comando:
<syntaxhighlight lang="bash">java -XshowSettings:properties -version 2>&1 > /dev/null | grep 'java.home'</syntaxhighlight>

Fichero de servicio de Kafka: <code>/etc/systemd/system/kafka.service</code>
<syntaxhighlight lang="bash"># /etc/systemd/system/kafka.service
[Unit]
Description=Apache Kafka
Requires=zookeeper.service
After=zookeeper.service

[Service]
Type=simple

User=kafka
Group=kafka
Environment=KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:/opt/kafka/kafka-config/log4j.properties"
Environment=KAFKA_HEAP_OPTS="-Xmx6G -Xms6G"
Enviroment=JAVA_HOME=/usr/lib/jvm/java-17-openjdk-17.0.10.0.7-2.el8.x86_64

ExecStart=/opt/kafka/kafka_2.13-3.7.0/bin/kafka-server-start.sh /opt/kafka/kafka-config/kafka.properties
ExecStop=/opt/kafka/kafka_2.13-3.7.0/bin/kafka-server-stop.sh

[Install]
WantedBy=multi-user.target</syntaxhighlight>

Una vez creado el fichero de servicio, se debe recargar el daemon de systemd y habilitar el servicio.
<syntaxhighlight lang="bash">sudo systemctl daemon-reload
sudo systemctl start kafka
# Comprobar que el servicio se ha iniciado correctamente
sudo systemctl status kafka
sudo systemctl enable kafka</syntaxhighlight>

== Verificación de Funcionamiento de Kafka ==

Para verificar que Kafka se ha instalado correctamente, se puede utilizar el comando <code>kafka-topics.sh</code> para crear un tópico.

=== Creación de Configuración de Producer ===

Se crea un fichero de configuración para el producer de prueba.

Fichero de configuración del producer: <code>/opt/kafka/kafka-config/producer.properties</code>
<syntaxhighlight lang="bash">compression.type=none
security.protocol=SSL
#!! Change to your keystore location and password
ssl.keystore.location=/opt/kafka/ssl/kafka.server.keystore.jks
ssl.keystore.password=!!sustituir_por_password!!
#!! Change to your key password
ssl.key.password=!!sustituir_por_password!!
#!! Change to your truststore location and password
ssl.truststore.location=/opt/kafka/ssl/kafka.server.truststore.jks
ssl.truststore.password=!!sustituir_por_password!!
ssl.endpoint.identification.algorithm=</syntaxhighlight>

Posteriormente, se ejecuta el comando de creación del topic:
<syntaxhighlight lang="bash">topicname="testtopic"
node_machinename="ln01kafklog01"
kafka-topics.sh --create --topic "$topicname" --bootstrap-server "SSL://$node_machinename:9092" --command-config /opt/kafka/kafka-config/producer.properties</syntaxhighlight>

Para elimitar el topic, se puede utilizar el comando:
<syntaxhighlight lang="bash">kafka-topics.sh --delete --topic "$topicname" --bootstrap-server "SSL://$node_machinename:9092" --command-config /opt/kafka/kafka-config/producer.properties</syntaxhighlight>

== Integración con OSB y Elastic ==

Para el uso de este cluster con otros servicios hay que realizar nuevas configuraciones.

A continuación se describen las configuraciones realizadas para su integración con OSB y Elastic.

&nbsp;

=== OSB ===
<div style="background:#eeeeee;border:1px solid #cccccc;padding:5px 10px;">
<span style="background:#eeeeee">cd /opt/kafka/ssl</span>

<span style="background:#eeeeee"># Se genera un truststore al que se le incluye el certificado CA.</span>

<span style="background:#eeeeee">keytool -keystore osb.server.truststore.jks -alias CARoot&nbsp;-import -file ca-cert -storepass "$pass"&nbsp;-keypass "$pass" -noprompt</span>

<span style="background:#eeeeee"># Se genera un nuevo keystore</span>

<span style="background:#eeeeee">keytool -genkey -keystore osb.server.keystore.jks -keyalg RSA -validity 3652 -storepass "$pass" -keypass "$pass" -dname "CN=osbstream" -storetype pkcs12</span><br/> <br/> <span style="background:#eeeeee"># Se genera una petición de firma de certificado</span>

<span style="background:#eeeeee">keytool -keystore osb.server.keystore.jks -certreq -file "osb-crq" -storepass "$pass" -keypass "$pass"</span>

<span style="background:#eeeeee"># Se firma la petición para generar el certificado osb-cert</span>

<span style="background:#eeeeee">openssl x509 -req -CA ./CA-files/ca-cert -CAkey ./CA-files/ca-key -in "osb-crq" -out osb-cert -days 365 -CAcreateserial -passin pass:"$pass"</span>

<span style="background:#eeeeee"># Se añade el certificado CA y el generado para OSB en el keystore</span>

<span style="background:#eeeeee">keytool -keystore osb.server.keystore.jks -alias CARoot -import -file ./CA-files/ca-cert -storepass "$pass" -keypass "$pass" -noprompt</span>

<span style="background:#eeeeee">keytool -keystore osb.server.keystore.jks -import -file osb-cert -storepass "$pass" -keypass "$pass" -noprompt</span>
</div> 
=== Elastic ===

Para Elastic se precisa configurar Kafka-connect.

Primerante se realizan las siguientes acciones de acuerdo a las instrucciones del equipo encargado de elastic:

*Se introduce el plugin <code>kafka-connect-elasticsearch-14.1.0-SNAPSHOT-jar-with-dependencies.jar</code>&nbsp;en el directorio<code>/opt/kafka/plugins.</code> 
*Se introduce en&nbsp;<code>/opt/kafka/ssl</code> un truststore de nombre<code>elastic-trust.jks</code> aportado por el equipo encargado de elastic. 
*Se introduce en <code>/opt/kafka/kafka-config</code> un fichero de configuración de nombre <code>connect-distributed.properties</code> aportado por el equipo encargado de elastic. 

Posteriormente, se realiza la configuración:
<div style="background:#eeeeee;border:1px solid #cccccc;padding:5px 10px;">
<span style="background:#eeeeee">cd /opt/kafka/ssl</span>

<span style="background:#eeeeee"># Se genera un nuevo keystore</span>

<span style="background:#eeeeee">keytool -genkey -keystore kafka-consumer.server.keystore.jks -keyalg RSA -validity 3652 -storepass "$pass" -keypass "$pass" -dname "CN=kafkaconsumer" -storetype pkcs12</span>

<span style="background:#eeeeee"># Se genera una petición de firma de certificado</span>

<span style="background:#eeeeee">keytool -keystore kafka-consumer.server.keystore.jks -certreq -file "consumer-cert-req" -storepass "$pass" -keypass "$pass"</span>

<span style="background:#eeeeee"># Se firma la petición</span>

<span style="background:#eeeeee">openssl x509 -req -CA ./CA-files/ca-cert -CAkey ./CA-files/ca-key -in "consumer-cert-req" -out cons-signed-cert -days 365 -CAcreateserial -passin pass:"$pass"</span>

<span style="background:#eeeeee"># Se añade el certificado CA y el generado para OSB en el keystore</span>

<span style="background:#eeeeee">keytool -keystore kafka-consumer.server.keystore.jks -alias CARoot -import -file ./CA-files/ca-cert -storepass "$pass" -keypass "$pass" -noprompt</span>

<span style="background:#eeeeee">keytool -keystore kafka-consumer.server.keystore.jks -import -file cons-signed-cert -storepass "$pass" -keypass "$pass" -noprompt</span>
</div> 
Como último paso, se crea un demonio para este servicio. Se crea para ello el fichero /etc/systemd/system/kafka-connect.service con el contenido:
<div style="background:#eeeeee;border:1px solid #cccccc;padding:5px 10px;">
<span style="background:#eeeeee">[Unit]<br/> Description=Apache Kafka-Connect<br/> Requires=kafka.service<br/> After=kafka.service</span>

<span style="background:#eeeeee">[Service]<br/> Type=simple</span>

<span style="background:#eeeeee">User=kafka<br/> Group=kafka</span>

<span style="background:#eeeeee">Environment=KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:/opt/kafka/kafka-config/log4j.properties"<br/> Environment=JAVA_HOME=/usr/lib/jvm/java-17-openjdk-17.0.10.0.7-2.el8.x86_64</span>

<span style="background:#eeeeee">ExecStart=/opt/kafka/kafka_2.13-3.7.0/bin/connect-distributed.sh /opt/kafka/kafka-config/connect-distributed.properties</span>

<span style="background:#eeeeee">[Install]<br/> WantedBy=multi-user.target</span>
</div> 
Una vez creado el fichero de servicio, se debe recargar el daemon de systemd y habilitar el servicio.
<syntaxhighlight lang="bash">sudo systemctl daemon-reload
sudo systemctl start zookeeper
# Comprobar que el servicio se ha iniciado correctamente
sudo systemctl status zookeeper
sudo systemctl enable zookeeper</syntaxhighlight>

= Modificaciones Posteriores =

== Depuración de logs ==

Para realizar la depuración de logs se valoró utilizar la modificación&nbsp;log4j, pero finalmente se creo un cron en cada máquina.

Dicho cron elimina&nbsp;todos los días a las 00:20 algunos logs de la carpeta /opt/kafka/kafka_2.13-3.7.0/logs al superar los 7&nbsp;días de antiguedad:
<syntaxhighlight lang="bash">
crontab -e ## Modificar el cron

20 0 * * * find /opt/kafka/kafka_2.13-3.7.0/logs -name 'controller.log.20*' -type f -mtime +7 -exec rm {} \;
20 0 * * * find /opt/kafka/kafka_2.13-3.7.0/logs -name 'log-cleaner.log.20*' -type f -mtime +7 -exec rm {} \;
20 0 * * * find /opt/kafka/kafka_2.13-3.7.0/logs -name 'server.log.20*' -type f -mtime +7 -exec rm {} \;
</syntaxhighlight>

= Reasignación de Topics y Particiones =

Al agregar nuevos brokers al clúster en activo, se vuelve necesario realizar reasignaciones en los tópics y particiones para poder rebalancear la carga de trabajo.

Puede visitarse [[Kafka._Reasignación_de_Topics_y_Particiones|este documento]] donde se explica en detalle las acciones a tomar.

&nbsp;

= Véase También =

== Referencias Externas ==

*[https://www.conduktor.io/kafka/how-to-install-apache-kafka-on-linux/ Guía General de Instalación de Kafka] 
*[https://kafka.apache.org/documentation/#java Notificaciones de Obsolescencia de Java] 
*[https://docs.aws.amazon.com/corretto/latest/corretto-17-ug/generic-linux-install.html Guía de Instalación de Java] 
*[https://docs.aws.amazon.com/corretto/latest/corretto-17-ug/downloads-list.html Descarga de Amazon Corretto] 
*[https://learn.microsoft.com/es-es/azure/hdinsight/kafka/apache-kafka-ssl-encryption-authentication Guía de Certificados Autofirmados por Microsoft] 
*[https://kafka.apache.org/downloads Descarga de Kafka] 
*[https://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html#sc_zkMulitServerSetup Documentación Oficial de Zookeeper sobre Ensemble] 
*[https://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html#sc_configuration Documentación Oficial de Zookeeper sobre Parámetros de Configuración] 
*[https://kafka.apache.org/documentation/#zk Notificaciones de Obsolescencia de Zookeeper] 
*[https://www.linuxtechi.com/how-to-create-lvm-partition-in-linux/ Guía de Creación de LVM] 
*[https://stackoverflow.com/questions/67705738/problem-with-kafka-failed-with-result-exit-code-status-1-failure Problema con JAVA_HOME en Servicio de Kafka] 
*[https://github.com/strimzi/strimzi-kafka-operator/issues/328#issuecomment-382307046 Configuración de Heap para Java] 